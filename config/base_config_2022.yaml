num_images:           20000
num_scenes:           5000
num_images_per_scene:   4
use_base_coordinate:    True
use_init_hand:          True
max_grasp_per_key_point: 20

hitdlr:
  15f:                  True
vis:
  vis_pointcloud:       True
  vis_scene:            True
  vis_handmesh:         True
  vis_obj_pointcloud:   True
color:
  plannar:              [150,150,150]
  object:               [255,215,0]
  pointcloud:           [0,255,0]
  bad_point:            [0,0,255]
  good_point:           [100,0,0]
  affordance_point:     [255,0,0]
  hand_mesh:            [255,255,0]
  Parallel_Extension:   [254,67,101,255]
  Pen_Pinch:            [252,157,154,255]
  Palmar_Pinch:         [200,200,169,255]
  Precision_Sphere:     [38,188,213,255]
  Large_Wrap:           [131,175,155,255]
dataset:
  num_points:           40000
  num_taxonomies:       5
  use_norm_points:      True
  sample_planar_rate:   0.10
train:
  batchsize:        1
  learning_rate:    0.01
  epoches:          80
  gpu:              [0]
  optimizer:        'Adam'
  workers:          1
  theme:            test
  gp_weight:        [1,10]
  afford_weight:    [1,5]
  printfreq:        50
  use_bin_loss:     False
  pretrain:         True
eval:
  model_path:       'experiment/20220617_111828_quat_loss8/checkpoints'
  epoch:            36
#  model_path:       'experiment/20220524_095650_quat_loss8/checkpoints'
#  epoch:            15
  dist_thresh:      0.05
  angle_thresh:     30
  quat_thresh:      60
bin_loss:
  azimuth_scope:        360
  azimuth_bin_size:     60
  elevation_scope:      90
  elevation_bin_size:   15
  grasp_angle_scope:    360
  grasp_angle_bin_size: 30
  depth_scope:          8
  depth_bin_size: 1
